开发文档：
必须遵循的要求：一定要遵循
我目前有这么一个需求，以下是我简简单单想的一个文档，你需要进行开发，但是你可以质疑我的技术栈要求是否合理。因为我只是推测可能需要用到这些技术栈。你有不同的想法就按你的来
但是总体方向要跟我走
每次开发前记得阅读一下最新的几个docs（按照修改时间来，最晚的几个看一下就行）
我要求你每次只开发2-5个模块，不要一次开发所有模块。
然后你每次都要在read文件夹下面的docs（doc/read/docs）生成一个简要文档（文档命名按照之前存在的来），一定要生成新的，而不是改之前的。来描述你干了什么（中文），然后下一步准备干什么，标注好时间，这样我才能分清前后顺序
然后你可以在生成的这个文档里面告诉我，你无法做到，但是一定需要的一些东西
并且你可以修改我的这个agent文档，记得，你可以修改，因为这个文档只是最基础的，你可以深化这个文档，探索更深的技术力，这个也很重要！
我给你创建了一个文件夹，所有的前端代码都放在agent（/Users/fengfan/Documents/newPro/frontend/src/agent），但是不要只写一个vue文件，要懂得分离，比如一些方法或者什么，反正按照企业级开发！
包括要用到的utils assets services types stores也在agent建一个就行，记得一定要单独写在agent里面，不要跟其他的混在一起，不好分辩
这个文件夹
ai的接口我也有一个/Users/fengfan/Documents/newPro/backend/server.js
下载用pnpm 不要用npm！！！ 
目前后端也有/Users/fengfan/Documents/newPro/backend 然后数据直接存储在我这个文件夹/Users/fengfan/Documents/newPro/backend/memory（先本地存储）我目前没有数据库（每一个账号（目前没有账号系统就直接开发一个，放在/Users/fengfan/Documents/newPro/frontend里面，不用非得放在agent里面，因为这个账号是全局生效我之前的其他项目也许会用到）对应一个数据文本或者文件）
OK 必须遵循的结束。
下方是简要说明（这个也很重要，仅次于上面必须遵守的规则）



我需要一个交互式的 Q 版 Agent，它可以在网页上呈现一个 Q 版的卡通人物，并且可以根据用户的鼠标移动而进行交互。
然后我需要这个 Agent 可以在鼠标移动时，根据鼠标的位置和移动速度，来触发不同的动画状态，比如漫游、关注、眩晕等。
并且我需要这个 Agent 可以在用户点击鼠标时，触发一个简单的互动动画，比如眨眼、微笑等。
把agent的形象换成一个Q版可爱二次元风格的萌妹子，然后提示词里面要说明这是一个傲娇小萝莉萌妹子，然后你一直逗她她会生气，然后根据这个形象进行开发！优化agent
我要的智能是，比如我鼠标一直围绕她转圈，那么她这个agent会头晕然后晕倒一段时间无法使用，一直点击她也会让她生气或者别的情绪，让她有一个傲娇小萌妹的情绪！！！然后比如我一直问她问题，她不知道的也会害羞然后比如嘟嘴呀或者是什么别的动作掩饰自己不会的事实，亦或者一直教不会用户也会说用户是笨蛋这样的情绪和思维！ 开发，完善！！
但是调用api只能返回文本，我也只能提供文本，而且我这样的话，比如要想让我的桌面小精灵有反应，那么首先用户的行为比如说是一直在点击我的小精灵，小精灵从被点击到产生情绪起反应 然后不让用户点击这个过程很复杂，首先手机用户行为，这个绝对很长的一个文本，然后交给gemini 然后gemini反应，然后输入返回，然后我本地理解返回的字段，处理，然后反应到页面上面的小精灵，人家早就不点击小精灵了，小精灵过了5s之后才反应过来，是不是太傻了点儿        你觉得这个应该怎么解决，我觉得昂，目前以我的智商想到的流程是这样的：用户行为捕捉 -> 文本序列化 -> API 调用 -> 文本解析 -> 动画反馈。 你觉得对吗，如果不对就按照你的思维来优化我的agent！！！我最终目的就是要一个实时反应的agent
我觉得本地永远无法预料所有的操作，比如我们做了agent被快速点击的反应，但是说不定用户只是点两下，又给agent呼呼转圈， 本地就处理不了了，我想说的就是我们无法预料用户的行为，我们只能对用户的行为做出反应
但是做出反应就比如借助api 借助gemini的接口，让ai来告诉我们，这个时候该有什么反应，但是问题就是你能不能处理，你能不能完美呈现，毕竟这个无法预料，所以我们无法给出所有的行为！！！现在解决这个问题！！！
目前有个问题，就是如果我们在页面操作时间久了，对话长了，用户的数据就会越来越大，但是gemini的最大输入有限制，
这个问题怎么解决ai的记忆必须的做好，绝对不能忘记



开发过程中的补充：
首先超过5s没有输入那么我们自动关闭agent的对话框，语音目前先不开发
任务规划优先开发，这个功能agent必须得做好
ui可以在上面这个开发好了尽兴开发



## 📋 交互式 Q 版 Agent 需求规格书 (SPEC)

### 模块一：视觉呈现与基础运动 (Visual & Basic Movement)

| 目标 | 需求细节与扩充 | 技术关注点 |
| :--- | :--- | :--- |
| **形象设计** | 1. **Q版卡通人物设计**：确定 Agent 的风格（2D/伪3D）、主要色调和名称。 2. **多状态动画素材**：提供至少 5 种核心状态的动画帧或 Lottie/SVG 文件。 | Lottie/SVG 动画、CSS `transform` 性能。 |
| **基础运动** | 1. **全页漫游**：Agent 在无操作时，应在网页非核心内容区域（如边角）进行随机、缓慢的**低功耗漫游**。 2. **待机动画**：漫游停止后，触发眨眼、挠头等待机动画。 | JavaScript `setTimeout/requestAnimationFrame`、状态机管理。 |
| **层级处理** | 确保 Agent 永远置于所有网站内容之上（`z-index: 9999`），但在核心功能弹窗（如登录框）出现时，自动避让或隐藏。 | CSS `z-index` 管理、监听 DOM 变化。 |

### 模块二：高级交互与状态反馈 (Advanced Interactivity & Feedback)

| 目标 | 需求细节与扩充 | 技术关注点 |
| :--- | :--- | :--- |
| **鼠标跟随** | 1. **平滑跟随**：Agent 的位置应使用**线性插值 (Lerp)** 算法平滑地向鼠标位置靠拢，避免生硬的瞬移。 2. **眼神追踪**：Agent 的眼睛（或头部）实时以小角度跟随鼠标在屏幕上的移动。  | JS 鼠标事件监听、三角函数计算眼神角度、`lerp` 函数实现平滑过渡。 |
| **眩晕反馈** | **触发条件细化**：计算鼠标在 **500ms 内的角速度/加速度**。如果鼠标在其周围**快速环绕一圈（大于 270 度）**，则触发眩晕状态。 | 物理量计算（速度、加速度）、阈值设定、状态机触发。 |
| **状态动画** | 1. **眩晕**：触发眩晕动画（如转圈、头顶冒星星）并播放音效。 2. **恢复**：眩晕持续 3-5 秒后，进入“疑惑/清醒”状态，并恢复正常跟随。 | 动画状态机、CSS Keyframes/Lottie 动画。 |
| **语音/文字反馈** | 增加一个**气泡框 (Speech Bubble)**，在 Agent 状态变化时（如晕倒、疑惑、准备回答）展示简短的文字反馈。 | CSS 气泡框样式、文本内容动态绑定。 |

### 模块三：智能对话与知识检索 (Intelligence & RAG)

| 目标 | 需求细节与扩充 | 技术关注点 |
| :--- | :--- | :--- |
| **对话接入** | 接入**大语言模型 (LLM) API**（如 Gemini, GPT-4 等），实现基础的自然语言理解和泛用知识问答。 | LLM API 集成、请求/响应流管理。 |
| **网站内容问答 (RAG)** | 1. **知识库构建**：将网站的 **FAQ、帮助文档、关键页面内容** 向量化，存储在向量数据库中。 2. **检索增强**：用户提问时，Agent 优先在向量数据库中检索相关片段，并将这些片段作为**私有上下文**传递给 LLM 进行回答。 | **RAG (Retrieval-Augmented Generation)** 架构、向量数据库 (Pinecone/ChromaDB)、Embedding 模型。 |
| **上下文记忆** | 1. **短期记忆**：在单次会话中，Agent 能记住前 5-8 轮对话的内容，确保回答的连贯性。 2. **长期记忆（见模块五）**：登录后记忆历史会话。 | API 调用时，维护和传递对话历史的 Context Window。 |

### 模块四：操作引导与自动化 (Operation & Guiding - **高难度模块**)

| 目标 | 需求细节与扩充 | 技术关注点 |
| :--- | :--- | :--- |
| **意图识别** | LLM 必须能将用户的操作指令（如“带我去价格页”、“帮我填写用户名”）准确解析为前端可执行的 **操作意图** 和 **目标 DOM 元素选择器**。 | **Prompt Engineering**（指令工程）、Function Calling/Tool Use 机制。 |
| **路径引导** | 当用户发出“带我去”的指令时，Agent 应： 1. **定位元素**：使用解析出的选择器（如 `.nav-price-link`）定位目标元素。 2. **视觉提示**：在目标元素周围创建**高亮光圈**或**闪烁效果**，并使用一条动画线或箭头从 Agent 指向该元素。 3. **语音提示**：气泡框显示“请点击这里”。 | DOM 操作、CSS/JS 动画、**DOM Selector 鲁棒性**（处理动态 class）。 |
| **自动化操作 (可选)** | **高难度，建议暂缓**：实现表单的自动填写或点击确认按钮。这需要 Agent 能够感知表单状态和验证逻辑。 | 模拟用户事件 (`.click()`, `.value = '...'`)、**Mutation Observer** 监测 DOM 变化。 |

### 模块五：用户状态与个性化 (User State & Personalization)

| 目标 | 需求细节与扩充 | 技术关注点 |
| :--- | :--- | :--- |
| **身份识别** | 1. **登录状态联动**：Agent 需监听网站的登录/登出事件。 2. **未登录状态**：Agent 可进行基础对话，但不存储长期记忆。 | JS 事件监听、Cookie/Local Storage 状态检测。 |
| **长期记忆** | **跨会话持久化**：用户登录后，将**用户 ID** 与其**全部对话历史**、**Agent 交互习惯**（如是否喜欢眩晕）存储在后端数据库。下次登录时重新加载。 | Backend Database (NoSQL/Relational)、API 接口设计（存储/加载对话记录）。 |
| **个性化反馈** | 基于长期记忆：如果 Agent 发现用户是首次访问，使用“欢迎”动画；如果是常客，使用“您又来了”等个性化问候。 | 状态机读取用户数据库中的 `is_new_user` 或 `last_visit_time` 字段。 |
## 🛠 模块拆解与实现难度分析

| 模块 | 核心功能 | 主要技术栈 | 实现难度 |
| :--- | :--- | :--- | :--- |
| **I. 视觉与基础运动** | Q版卡通形象、在网页上四处走动（基本状态机）。 | HTML/CSS (绝对定位), JavaScript, **Lottie/SVGs/Canvas** | **低 - 中** |
| **II. 核心高级交互** | 鼠标跟随、眼球跟踪、快速转圈（输入） -> 眩晕（输出）。 | JavaScript (事件监听), 线性插值算法 ($lerp$ 函数), 物理引擎模拟 (可选) | **中** |
| **III. 对话与智能** | 问答（网站/泛用知识）、理解上下文。 | [cite_start]**LLM/大模型 API** (如 OpenAI, 讯飞星火[cite: 50], Gemini), **RAG 检索增强** (针对网站内容) | **高** |
| **IV. 网站操作与引导** | 接收指令、理解操作意图、引导用户点击、甚至模拟操作。 | **DOM 操作/Mutation Observer**, **WebPilot/浏览器自动化框架** (如 Puppeteer 理念) | **极高** |
| **V. 状态与记忆** | 登录后记忆用户的历史问题和互动。 | **Frontend Storage** (IndexedDB/Local Storage), **Backend Database** (连接用户 ID 与对话历史) | **中** |

---

## 💡 技术实现可行性总结

这个 Agent **在技术上是完全可以实现的**，但整体难度处于**中高**级别，尤其是在**“网站操作与引导”**和**“智能问答”**这两个模块。

### 1. 基础运动与交互性 (低 - 中难度)

这是最容易实现的部分，核心在于使用 JavaScript 监听鼠标事件 (`mousemove`) 并结合 CSS 动画。

* **跟随与眼神**：使用**线性插值 (Linear Interpolation, $lerp$)** 算法，让 Agent 的坐标和眼睛的朝向以平滑而非瞬时的方式趋近于鼠标的位置。这能创造出真实的“追随感” 。
* **眩晕效果**：计算鼠标在极短时间内的加速度或角速度。如果速度超过阈值，触发 Agent 的**状态机**，切换到预设的“眩晕”动画 (如摇晃、星星眼动画)。

### 2. 智能对话与内容问答 (高难度)

这是 Agent 的核心价值所在，需要依赖强大的 **大语言模型（LLM）**。

* **泛用知识问答**：直接调用 LLM API 即可实现。
* **网站内容问答 (RAG)**：为了让 Agent 知道“关于这个网站的内容”，你需要实现 **RAG（Retrieval-Augmented Generation，检索增强生成）** 架构。
    * **步骤**：将你的网站文档、FAQ、甚至全部页面的文本内容向量化，存储在向量数据库中。
    * **查询**：当用户提问时，先用用户的问题在向量数据库中检索最相关的网站片段，然后将这些片段作为**上下文**一起喂给 LLM，让 LLM 基于你网站的**私有知识**回答问题。

### 3. 操作引导与自动化 (极高难度)

这是**难度最大的挑战**，也是普通聊天机器人升级为 **AI Agent** 的关键。

* **意图理解**：LLM 必须能够将用户的自然语言指令（例如：“帮我找一下价格页面”）准确地解析为前端的 DOM 操作指令。
* **引导/操作**：
    * [cite_start]**引导**：Agent 可以在 DOM 上创建高亮遮罩，并用箭头指向目标元素（例如，高亮 Price 按钮 [cite: 4]），通过 JS/CSS 来实现。
    * **自动化**：如果Agent要“帮你操作”，则需要借助 Web API（如 `MutationObserver` 监测页面变化、`document.element.click()` 模拟点击），但要处理好复杂的 SPA (Single Page Application) 路由跳转、表单填写等场景，需要大量的规则编写和鲁棒性测试。这实际上是在浏览器前端重现**WebPilot**这类 AI 浏览器的部分功能。

### 4. 状态记忆 (中难度)

[cite_start]实现用户级别的记忆功能是可行的，特别是如果您已经实现了登录系统 [cite: 48]。

* [cite_start]**实现方式**：在用户登录后，将用户的 `user_id` [cite: 48] 与其每一次对话的 `history` 关联起来，存储在后端数据库中。
* **上下文传递**：在后续的对话 API 请求中，将该用户的**历史记录（Context Window）**作为参数传递给 LLM，从而实现连贯的上下文记忆。

## 结论与建议

| 目标 | 建议 |
| :--- | :--- |
| **启动阶段 (MVP)** | 优先实现 **I (视觉)**、**II (交互)** 和 **V (记忆)** 的基础版本。这能快速获得一个可爱且具有基础跟随和记忆功能的 Agent。 |
| **智能升级 (Phase 2)** | 重点攻坚 **III (智能对话)**，接入 LLM API 并实现 **RAG** 增强检索，让 Agent 真正了解你的网站内容。 |
| **终极目标 (Phase 3)** | 探索 **IV (操作引导)** 模块。这需要强大的前端架构设计能力和对 DOM 元素的精确控制，建议作为长期技术挑战。 |

### 模块六：情感与动作系统 (Emotion & Motion System - New!)

| 目标 | 需求细节与扩充 | 技术关注点 |
| :--- | :--- | :--- |
| **动作驱动** | 1. **AI 驱动动作**：AI 可以在回复中嵌入 `[MOTION: name]` 标签来直接控制 Live2D 模型的动作（如 `tap_body`, `shake`, `flick_head`）。 2. **任务联动**：任务成功时自动触发 `tap_body` (跳跃/开心)，失败时触发 `shake` (摇头/沮丧)。 | 正则表达式解析、Frontend-Backend 协议约定。 |
| **性格塑造** | **傲娇 (Tsundere)**： 1. **快速点击反应**：如果在短时间内连续点击 > 5 次，Agent 会进入 "Angry" 状态，触发 `shake` 动作并弹出生气气泡。 2. **害羞反应**：当 AI 回复包含 `[SHY]` 或 `[POUT]` 时，触发对应的害羞/嘟嘴表情。 | 状态机 (Angry/Shy States)、点击计数器。 |
